

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta property="og:title" content="Random Variables" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://cranmer.github.io/stats-ds-book/random_variables.html" />
  <meta property="og:description" content="The basic idea of random variables is inuitive and familiar for physicists, and it is perhapse the fundamental idea in probabilistic thinking. At the same time, randomness is at the heart of some o..." />
  <meta property="og:image" content="https://cranmer.github.io/stats-ds-book/_images/Neyman-pearson.006.png" />
  
    <title>Random Variables &#8212; Statistics and Data Science</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/segment.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/menu.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/pdf_print.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-index--0afa1ebdab0bb23b98b56d34c23d9f57.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-variables--ffc7f74dcb1b9eecba2dbcbc22818714.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/save_state.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "indep": "{\\perp\\kern-5pt\\perp}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "bered": ["\\color{#DC2830}{#1}", 1], "ecol": ["}}"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Conditonal Probability" href="conditional.html" />
    <link rel="prev" title="Probability Topics" href="probability-topics.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Statistics and Data Science</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Statistics and Data Science
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="schedule.html">
   Draft Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="jupyterhub.html">
   JupyterHub for class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discussion_forum.html">
   Discussion Forum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="preliminaries.html">
   Preliminaries
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Probability
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="reference internal" href="probability-topics.html">
   Probability Topics
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conditional.html">
     Conditonal Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bayes_theorem.html">
     Bayes’ Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="independence.html">
     Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="empirical_distribution.html">
     Empirical Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="expectation.html">
     Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="correlation.html">
     Covariance and Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasaurus-long.html">
     Simple data exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/visualize_marginals.html">
     Visualizing joint and marginal distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="measures_of_dependence.html">
     Quantifying statistical dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/change-of-variables.html">
     How do distributions transform under a change of variables ?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/one-over-x-flow.html">
     Change of variables with autodiff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/likelihood-change-obs.html">
     Transformation of likelihood with change of random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/invariance-of-likelihood-to-reparameterizaton.html">
     Transformation properties of the likelihood and posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="error-propagation/investigating-propagation-of-errors.html">
     Investigating propagation of errors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="error-propagation/error_propagation_with_jax.html">
     Revisiting error propagation with automatic differentiation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/accept-reject.html">
     Accept / Reject Monte Carlo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/Binomial_histograms-interactive.html">
     An interactive exploration of statistical fluctuations in histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pgm/daft.html">
     Visualizing Graphical Models
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="statistics-topics.html">
   Statistics Topics
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_pearson.html">
     Neyman-Pearson lemma
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_construction.html">
     Neyman construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lhc_stats_thumbnail.html">
     Thumbnail of LHC Statistical Procedures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="statistical_decision_theory.html">
     Statistical decision theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="probprog/MarkovPath.html">
     Universal Probabilistic Programming Example
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="prml_notebooks/attribution.html">
   PRML Examples
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch01_Introduction.html">
     1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch02_Probability_Distributions.html">
     2. Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch03_Linear_Models_for_Regression.html">
     3. Linear Models for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch04_Linear_Models_for_Classfication.html">
     4. Linear Models for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch05_Neural_Networks.html">
     5. Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch06_Kernel_Methods.html">
     6. Kernel Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch07_Sparse_Kernel_Machines.html">
     7. Sparse Kernel Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch08_Graphical_Models.html">
     8. Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch09_Mixture_Models_and_EM.html">
     9. Mixture Models and EM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch10_Approximate_Inference.html">
     10. Approximate Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch11_Sampling_Methods.html">
     11. Sampling Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch12_Continuous_Latent_Variables.html">
     12. Continuous Latent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch13_Sequential_Data.html">
     13. Sequential Data
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Software and Computing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="computing-topics.html">
   Software &amp; Computing Topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="autodiff-tutorial.html">
   Tutorial on Automatic Differentiation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data Science
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="data-science-topics.html">
   Data Science Topics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="other_resources.html">
   Other Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="built-on.html">
   Built on
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Jupyter Book Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cheatsheet.html">
   MyST Cheat Sheet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   Content with notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interactive.html">
   Interactive data visualizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="test_embed_video.html">
   Test Embed Video
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nbgrader.html">
   nbgrader
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/random_variables.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/cranmer/stats-ds-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/cranmer/stats-ds-book/issues/new?title=Issue%20on%20page%20%2Frandom_variables.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/cranmer/stats-ds-book/edit/master/book/random_variables.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cumulative-distributions">
   Cumulative distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#futher-reading">
   Futher reading
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="random-variables">
<h1>Random Variables<a class="headerlink" href="#random-variables" title="Permalink to this headline">¶</a></h1>
<p>The basic idea of <strong>random variables</strong> is inuitive and familiar for physicists, and it is perhapse <em>the</em> fundamental idea in probabilistic thinking.
At the same time, randomness is at the heart of some of the deepest mysteries of physics: the transition from the determinism of classical mechanics to indeterminism in quantum mechanics.
Furthermore, the notation and terminology used by statisticians is often unfamiliar or awkward to physicists and the rigorous mathematical treatment of random variables may seem overly formal and opaque.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The  <a class="reference external" href="http://cs229.stanford.edu/section/cs229-prob.pdf">Stanford lectures on Probability and statistics</a> and the  <a class="reference external" href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">NYU CDS lecture notes on Probability and Statistics</a> both start from the formal definition of Probability Spaces, but let’s start with something a little more intuitive.</p>
</div>
<p>To start with we will make the distinction between two types of random variables:</p>
<ul class="simple">
<li><p><strong>Discrete random variables</strong> : e.g. the flip of a coin, the roll of a die, the number of decays of a radioactive substance in a fixed time interval, etc.</p></li>
<li><p><strong>Continuous random variables</strong> : e.g. the height of a person, the mass of a star, the time interval between two subsequent radioactive decays, etc.</p></li>
</ul>
<p>In both cases we have in mind the notion of an underlying <strong>population</strong> and the particular values that different instances (or <strong>realizations</strong>) that these random values may take. The realizations are random draws from some population: e.g. the height of a particular person drawn from a population of people, the mass of a particular star drawn from a population of stars, the result of a particular flip of a coin drawn from a (potentially hypothetical) population of coin flips. Consider this quote from the  <a class="reference external" href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">NYU CDS lecture notes on Probability and Statistics</a>:</p>
<div class="note admonition">
<p class="admonition-title">Notation</p>
<p>A random variable quantifies our uncertainty about the quantity it represents, not the value that it happens to finally take once the outcome is revealed. You should <em>never</em> think of a random variable as having a fixed numerical value. If the outcome is known, then that determines a realization of the random variable. In order to stress the difference between random variables and their realizations, we denote the former with uppercase letters <span class="math notranslate nohighlight">\((X, Y , . . . )\)</span> and the latter with lowercase letters <span class="math notranslate nohighlight">\((x, y, . . . )\)</span>.</p>
</div>
<p>We often say that the random variable <span class="math notranslate nohighlight">\(X\)</span> is <strong>distributed</strong> according to a certain distribution denoted <span class="math notranslate nohighlight">\(p_X\)</span>.  It is also useful to denote <span class="math notranslate nohighlight">\(\mathbb{X}\)</span> for the space that the realizations <span class="math notranslate nohighlight">\(x\)</span> live in (eg. natural numbers <span class="math notranslate nohighlight">\(\mathbb{N}\)</span>, real numbers <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, d-dimensional Euclidean space <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, etc.), In order to refer to the probability (density) that the random variable <span class="math notranslate nohighlight">\(X\)</span> takes on the value <span class="math notranslate nohighlight">\(x\)</span>, we write <span class="math notranslate nohighlight">\(p_X(X=x)\)</span> (often shortened to <span class="math notranslate nohighlight">\(p_X(x)\)</span> or just <span class="math notranslate nohighlight">\(p(x)\)</span> if the context is clear).</p>
<div class="admonition-terminology admonition">
<p class="admonition-title">Terminology</p>
<p>Statisticians often links the type of random variable with its distribution (eg. “a Poisson random variable” or “a Gaussian random variable”) as opposed to the data type the realization take on (i.e. a natural number or a real number).</p>
</div>
<p>It is important to make the distinction between the discrete and continous cases:</p>
<ul class="simple">
<li><p><strong>Probability Mass Function</strong> (pmf) describes the distribution of a discrete random variables (eg. <span class="math notranslate nohighlight">\(x\in \mathbb{N}\)</span>), and <span class="math notranslate nohighlight">\(p_X(x)\)</span> is unitless (or has “units of probability”)</p></li>
<li><p><strong>Probability Density Functions</strong> (pdf) describes the distribution of a continuous random variable (eg. <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>), and <span class="math notranslate nohighlight">\(p_X(x)\)</span> has units of probability per unit <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
</ul>
<p>This is analogous to thinking of point masses or point charges in space versus  mass-density or charge-density distributed along a line, surface, or volume.
Just as the mass or charge in a region is the integral of this mass-density or charge-density in that region, the probability that a continous <span class="math notranslate nohighlight">\(x\)</span> falls in some region <span class="math notranslate nohighlight">\(W \in \mathbb{X}\)</span> is <span class="math notranslate nohighlight">\(P(x\in W) = \int_W p_X(x) dx\)</span>.</p>
<p>These distributions have a few intuitive properties, which correspond to the <a class="reference internal" href="bayes_theorem.html#axioms-of-prob"><span class="std std-ref">axioms of probability</span></a>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\sum_{x} p_X(x) = 1\)</span> or in the continous case  <span class="math notranslate nohighlight">\(\int dx p_X(x) = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p_X(x) \ge 0\)</span> for all <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>if <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are mutually exclusive  (or disjoint so that their intersection is empy, <span class="math notranslate nohighlight">\(A \cap B = \emptyset\)</span> ), then <span class="math notranslate nohighlight">\(p(A \cup B) = p(A)+p(B)\)</span>. For continuous variables, you could write <span class="math notranslate nohighlight">\(\int_{A \cup B} p_X(x) dx = \int_{A} p_X(x) dx + \int_{B} p_X(x) dx\)</span></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the continous case it is totally fine for the probability density <span class="math notranslate nohighlight">\(p_X(x)&gt;1\)</span>. Consider a Gaussian distribution with <span class="math notranslate nohighlight">\(\sigma = 0.01\)</span>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is somewhat common that probability density functions are denoted <span class="math notranslate nohighlight">\(f(X)\)</span> instead of <span class="math notranslate nohighlight">\(p(X)\)</span> or to use a capital <span class="math notranslate nohighlight">\(P(X)\)</span> to denote probability and a lower-case <span class="math notranslate nohighlight">\(p(X)\)</span> to denote a probability density. Usually, this can be sorted out from context.</p>
</div>
<p>In terms of notation, it is common to see <span class="math notranslate nohighlight">\(X \sim p_X\)</span>, which is read as “(the random variable) <span class="math notranslate nohighlight">\(X\)</span> is distributed as (the distribution) <span class="math notranslate nohighlight">\(p_X\)</span>”. Sometimes one may also see <span class="math notranslate nohighlight">\(X \sim p_X(\cdot)\)</span>. This notation really emphasizes <span class="math notranslate nohighlight">\(X\)</span> as a random variable and <span class="math notranslate nohighlight">\(p_X\)</span> as a distribution, and with this notation it does not make sense to write <span class="math notranslate nohighlight">\(x \sim p_X\)</span>. However, it is fairly common in some areas of physics to write <span class="math notranslate nohighlight">\(p(x)\)</span> to refer to the distribution with the idea that <span class="math notranslate nohighlight">\(x\)</span> is the explicit realization of a random variable, but the argument to a function. These notational issues may seem overstated in this document, but it is my experience that it is a barier to physicists reading the statistics literature and a fundamental cause of needless reinvention of the wheel.</p>
<div class="section" id="cumulative-distributions">
<h2>Cumulative distributions<a class="headerlink" href="#cumulative-distributions" title="Permalink to this headline">¶</a></h2>
<p>A related concepts is the <strong>cumulative distribution function</strong> (cdf) for a real-valued random variable <span class="math notranslate nohighlight">\(X\)</span>, which is defined as the probability the random variable <span class="math notranslate nohighlight">\(X\)</span> is less than or equal to some particular value <span class="math notranslate nohighlight">\(x\)</span></p>
<div class="math notranslate nohighlight">
\[
F_X(x) := P(X \le x) 
\]</div>
<p>I think that it is inuitive for physicists to think of a proability density function as the fundamental object and to define <span class="math notranslate nohighlight">\(F_X(x) = \int_{-\infty}^x p_X(x) dx\)</span>; however, typically the formal approach is the opposite and one defines</p>
<div class="math notranslate nohighlight">
\[
p_X(x) := \frac{dF_X}{dx} .
\]</div>
<p>This kind of fine print matters is important formally in cases where the derivative of <span class="math notranslate nohighlight">\(F_X(x)\)</span> does not exist, but rarely matters in practice.</p>
<p>So what about continous multivariate data <span class="math notranslate nohighlight">\(x \in \mathbb{R}^d\)</span>? How does one define a cumulative distribuiton in that case? The integral “from minus infinity to <span class="math notranslate nohighlight">\(x\)</span>” doesn’t seem to make sense, or at least it is ambiguous. Say we have two continous random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, then one can define the <strong>joint cumulative distribution function</strong></p>
<div class="math notranslate nohighlight">
\[
F_{XY}(x,y) := P(X\le x, Y\le y), 
\]</div>
<p>ie. the probability that the random variable <span class="math notranslate nohighlight">\(X \le x\)</span> <em>and</em> <span class="math notranslate nohighlight">\(Y \le y\)</span>. Personally, this always bothered me as a physicist because it seems like it is sensitive to an arbitrary choice of axes for my two dimensional data. But mathematically, it works for formally defining what to me is a more natural <strong>joint probability density function</strong></p>
<div class="math notranslate nohighlight">
\[
p_{XY}(x,y) := \frac{\partial^2 F_{XY}(x,y)}{\partial x \partial y}.
\]</div>
<p>The generalizatio to data in <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> is straight forward with the <span class="math notranslate nohighlight">\(d^\textrm{th}\)</span> partial derivative. (Note, at this point in Secton 3.2 of  <a class="reference external" href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">NYU CDS lecture notes on Probability and Statistics</a> the notation for the joint pdf changes to <span class="math notranslate nohighlight">\(f_{XY}(x,y)\)</span>)</p>
</div>
<div class="section" id="futher-reading">
<h2>Futher reading<a class="headerlink" href="#futher-reading" title="Permalink to this headline">¶</a></h2>
<p>With this introduction, I invite you to read the <a class="reference external" href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">NYU CDS lecture notes on Probability and Statistics</a> Sections 2.1-2.3, 3.1-3.3.
As you will find, this requires understanding the notion of a <strong>probability space</strong>, a <strong>sample space</strong>, a <strong>probability measure</strong>, and the mathematical concept of a <span class="math notranslate nohighlight">\(\sigma\)</span><strong>-algebra</strong>. These are defined and discussed in Section 1.</p>
<p>You may also be interested in reading about the idea of a <a class="reference external" href="https://en.wikipedia.org/wiki/Copula_(probability_theory)">Copula</a>, which relates the cumulative distribution functions for individual random variables (marginals) <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> to the joint distribution.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The formal treatments of probability spaces makes subtle distinctions between terms like <em>event</em>,  <em>observation</em>, <em>sample</em>, and <em>outcome</em>, which physicists may tend to use interchangibly. Furthermore, in causal inference there is a distinction made between <em>observational studies</em> and <em>experiments</em>.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="probability-topics.html" title="previous page">Probability Topics</a>
    <a class='right-next' id="next-link" href="conditional.html" title="next page">Conditonal Probability</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Kyle Cranmer<br/>
        
            &copy; Copyright .<br/>
          <div class="extra_footer">
            <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>