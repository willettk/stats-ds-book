{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting error propagation with automatic differentiation\n",
    "\n",
    "By Kyle Cranmer, March 2, 2020\n",
    "\n",
    "This notebook is dedicated to Feeman Dyson, who died on February 28, 2020 in Princeton, NJ at the age of 96.\n",
    "\n",
    "“New directions in science are launched by new tools much more often than by new concepts. The effect of a concept-driven revolution is to explain old things in new ways. The effect of a tool-driven revolution is to discover new things that have to be explained.”\n",
    "\n",
    "-- Freeman Dyson\n",
    "\n",
    "![](https://www.ias.edu/sites/default/files/styles/grid_feature_teaser/public/Dyson_Freeman_Dyson_20151016_DKomoda-5376%20%281200%29.jpg?itok=oGwqWjL8![image.png](attachment:image.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder of propagation of errors \n",
    "\n",
    "This notebook was made to investigate the propagation of errors formula.\n",
    "We imagine that we have a function $q(x,y)$ and we want to propagate the\n",
    "uncertainty on $x$ and $y$ (denoted $\\sigma_x$ and $\\sigma_y$, respectively) through to the quantity $q$.\n",
    "\n",
    "The most straight forward way to do this is just randomly sample $x$ and $y$, evaluate $q$ and look at it's distribution. This is really the definition of what we mean by propagation of uncertianty. It's very easy to do with some simply python code.\n",
    "\n",
    "The calculus formula for the propagation of errors is really an approximation. This is the formula for a general $q(x,y)$\n",
    "\\begin{equation}\n",
    "\\sigma_q^2 = \\left( \\frac{\\partial q}{\\partial x} \\sigma_x \\right)^2 + \\left( \\frac{\\partial q}{\\partial y}\\sigma_y \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "In the special case of addition  $q(x,y) = x\\pm y$ we have $\\sigma_q^2 = \\sigma_x^2 + \\sigma_y^2$.\n",
    "\n",
    "In the special case of multiplication $q(x,y) = x y$ and division $q(x,y) = x / y$ we have $(\\sigma_q/q)^2 = (\\sigma_x/x)^2 + (\\sigma_y/y)^2$, which we can rewrite as $\\sigma_q = (x/y) \\sqrt{(\\sigma_x/x)^2 + (\\sigma_y/y)^2}$\n",
    "\n",
    "Let's try out these formulas and compare the direct approach of making the distribution to the prediction from these formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation\n",
    "\n",
    "\n",
    "\n",
    "Excerpts from the Wikipedia article: https://en.wikipedia.org/wiki/Automatic_differentiation\n",
    "\n",
    "In mathematics and computer algebra, automatic differentiation (AD), also called algorithmic differentiation or computational differentiation,[1][2] is a set of techniques to numerically evaluate the derivative of a function specified by a computer program. AD exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to working precision, and using at most a small constant factor more arithmetic operations than the original program.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/AutomaticDifferentiationNutshell.png/600px-AutomaticDifferentiationNutshell.png)\n",
    "\n",
    "Usually, two distinct modes of AD are presented, forward accumulation (or forward mode) and reverse accumulation (or reverse mode). Forward accumulation specifies that one traverses the chain rule from inside to outside (that is, first compute \n",
    "${\\displaystyle dw_{1}/dx}$ and then \n",
    "${\\displaystyle dw_{2}/dw_{1}}$ and at last \n",
    "${\\displaystyle dy/dw_{2}})$, while reverse accumulation has the traversal from outside to inside (first compute \n",
    "${\\displaystyle dy/dw_{2}}$ and then \n",
    "${\\displaystyle dw_{2}/dw_{1}}$ and at last \n",
    "${\\displaystyle dw_{1}/dx})$. More succinctly,\n",
    "\n",
    " * forward accumulation computes the recursive relation: \n",
    "${\\displaystyle {\\frac {dw_{i}}{dx}}={\\frac {dw_{i}}{dw_{i-1}}}{\\frac {dw_{i-1}}{dx}}}$ with \n",
    "${\\displaystyle w_{3}=y}$, and,\n",
    "\n",
    " * reverse accumulation computes the recursive relation: \n",
    "${\\displaystyle {\\frac {dy}{dw_{i}}}={\\frac {dy}{dw_{i+1}}}{\\frac {dw_{i+1}}{dw_{i}}}}$ with \n",
    "${\\displaystyle w_{0}=x}$.\n",
    "\n",
    "<!--\n",
    "\n",
    "\n",
    "Fundamental to AD is the decomposition of differentials provided by the chain rule. For the simple composition\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle {\\begin{aligned}y&=f(g(h(x)))=f(g(h(w_{0})))=f(g(w_{1}))=f(w_{2})=w_{3}\\\\w_{0}&=x\\\\w_{1}&=h(w_{0})\\\\w_{2}&=g(w_{1})\\\\w_{3}&=f(w_{2})=y\\end{aligned}}}\n",
    "\\end{equation}\n",
    "the chain rule gives\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle {\\frac {dy}{dx}}={\\frac {dy}{dw_{2}}}{\\frac {dw_{2}}{dw_{1}}}{\\frac {dw_{1}}{dx}}}\n",
    "\\end{equation}\n",
    "Usually, two distinct modes of AD are presented, forward accumulation (or forward mode) and reverse accumulation (or reverse mode). Forward accumulation specifies that one traverses the chain rule from inside to outside (that is, first compute ${\\displaystyle dw_{1}/dx}$ and then \n",
    "${\\displaystyle dw_{2}/dw_{1}}$ and at last \n",
    "${\\displaystyle dy/dw_{2}})$, while reverse accumulation has the traversal from outside to inside (first compute \n",
    "${\\displaystyle dy/dw_{2}}$ and then \n",
    "${\\displaystyle dw_{2}/dw_{1}}$ and at last \n",
    "${\\displaystyle dw_{1}/dx})$. More succinctly,\n",
    "forward accumulation computes the recursive relation: \n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle {\\frac {dw_{i}}{dx}}={\\frac {dw_{i}}{dw_{i-1}}}{\\frac {dw_{i-1}}{dx}}} \n",
    "\\end{equation}\n",
    "with \n",
    "${\\displaystyle w_{3}=y}$, and,\n",
    "reverse accumulation computes the recursive relation: \n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle {\\frac {dy}{dw_{i}}}={\\frac {dy}{dw_{i+1}}}{\\frac {dw_{i+1}}{dw_{i}}}}\n",
    "\\end{equation}\n",
    "with ${\\displaystyle w_{0}=x}$.\n",
    "Generally, both forward and reverse accumulation are specific manifestations of applying the operator of program composition, fixing the appropriate one of the two mappings \n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle (w,y)}.\n",
    "\\end{equation}\n",
    "\n",
    "### Forward mode\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/ForwardAccumulationAutomaticDifferentiation.png/600px-ForwardAccumulationAutomaticDifferentiation.png)\n",
    "\n",
    "In forward accumulation AD, one first fixes the independent variable with respect to which differentiation is performed and computes the derivative of each sub-expression recursively. In a pen-and-paper calculation, this involves repeatedly substituting the derivative of the inner functions in the chain rule:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle {\\frac {\\partial y}{\\partial x}}={\\frac {\\partial y}{\\partial w_{n-1}}}{\\frac {\\partial w_{n-1}}{\\partial x}}={\\frac {\\partial y}{\\partial w_{n-1}}}\\left({\\frac {\\partial w_{n-1}}{\\partial w_{n-2}}}{\\frac {\\partial w_{n-2}}{\\partial x}}\\right)={\\frac {\\partial y}{\\partial w_{n-1}}}\\left({\\frac {\\partial w_{n-1}}{\\partial w_{n-2}}}\\left({\\frac {\\partial w_{n-2}}{\\partial w_{n-3}}}{\\frac {\\partial w_{n-3}}{\\partial x}}\\right)\\right)=\\cdots }\n",
    "\\end{equation}\n",
    "This can be generalized to multiple variables as a matrix product of Jacobians.\n",
    "\n",
    "\n",
    "### Reverse mode\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/ReverseaccumulationAD.png/600px-ReverseaccumulationAD.png)\n",
    "\n",
    "In reverse accumulation AD, the dependent variable to be differentiated is fixed and the derivative is computed with respect to each sub-expression recursively. In a pen-and-paper calculation, the derivative of the outer functions is repeatedly substituted in the chain rule:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\frac  {\\partial y}{\\partial x}}={\\frac  {\\partial y}{\\partial w_{1}}}{\\frac  {\\partial w_{1}}{\\partial x}}=\\left({\\frac  {\\partial y}{\\partial w_{2}}}{\\frac  {\\partial w_{2}}{\\partial w_{1}}}\\right){\\frac  {\\partial w_{1}}{\\partial x}}=\\left(\\left({\\frac  {\\partial y}{\\partial w_{3}}}{\\frac  {\\partial w_{3}}{\\partial w_{2}}}\\right){\\frac  {\\partial w_{2}}{\\partial w_{1}}}\\right){\\frac  {\\partial w_{1}}{\\partial x}}=\\cdots \n",
    "\\end{equation}\n",
    "\n",
    "-->\n",
    "\n",
    "\n",
    "We will use \n",
    "https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad, jacfwd\n",
    "import jax.numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here are 3 lines of code for the propagation of uncertainty formula\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_q = \\sqrt{\\left( \\frac{\\partial q}{\\partial x} \\sigma_x \\right)^2 + \\left( \\frac{\\partial q}{\\partial y}\\sigma_y \\right)^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_jax_gen(q,x,dx):\n",
    "    jac = jacfwd(q)\n",
    "    return np.sqrt(np.sum(np.power(jac(x)*dx,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup two observations with uncertainties\n",
    "\n",
    "Below I'll use $x$ and $y$ for symbols, but they will be stored in the array `x` so that `x[0]=`$x$ and `x[1]=$y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cranmer/anaconda3/envs/jax-md/lib/python3.6/site-packages/jax/lib/xla_bridge.py:120: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "x_ = np.array([2.,3.])\n",
    "dx_ = np.array([.1,.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition and Subtraction\n",
    "\n",
    "\n",
    "In the special case of addition  $q(x,y) = x\\pm y$ we have $\\sigma_q^2 = \\sigma_x^2 + \\sigma_y^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return x[0]+x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_classic(x, dx):\n",
    "    # for q = x[0]*x[1]\n",
    "    ret = dx[0]**2 + dx[1]**2\n",
    "    return np.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  5.0 +/- 0.14142136\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_classic(x_, dx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  5.0 +/- 0.14142136\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplication and Division\n",
    "\n",
    "In the special case of multiplication \n",
    "\\begin{equation}\n",
    "q(x,y) = x y\n",
    "\\end{equation}\n",
    "and division \n",
    "\\begin{equation}\n",
    "q(x,y) = \\frac{x}{y}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(\\sigma_q/q)^2 = (\\sigma_x/x)^2 + (\\sigma_y/y)^2\n",
    "\\end{equation}\n",
    "which we can rewrite as\n",
    "\\begin{equation}\n",
    "\\sigma_q = (x/y) \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return x[0]*x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_classic(x, dx):\n",
    "    # for q = x[0]*x[1]\n",
    "    ret = (dx[0]/x[0])**2 + (dx[1]/x[1])**2 \n",
    "    return (x[0]*x[1])*np.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  6.0 +/- 0.36055514\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_classic(x_, dx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  6.0 +/- 0.36055514\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return x[0]/x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_classic(x, dx):\n",
    "    # for q = x[0]*x[1]\n",
    "    ret = (dx[0]/x[0])**2 + (dx[1]/x[1])**2 \n",
    "    return (x[0]/x[1])*np.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  0.6666667 +/- 0.040061682\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_classic(x_, dx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  0.6666667 +/- 0.040061682\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powers\n",
    "\n",
    "$q(x,y) = x^m y^n$ \n",
    "we have \n",
    "\n",
    "\\begin{equation}\n",
    "(\\sigma_q/q)^2 = \\left(|m|\\frac{\\sigma_x}{x}\\right)^2 + \\left(|n|\\frac{\\sigma_y}{y}\\right)^2\n",
    "\\end{equation}\n",
    "which we can rewrite as \n",
    "\\begin{equation}\n",
    "\\sigma_q = x^m y^n \\sqrt{\\left(|m|\\frac{\\sigma_x}{x}\\right)^2 + \\left(|n|\\frac{\\sigma_y}{y}\\right)^2}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x, m=2, n=3):\n",
    "    return np.power(x[0],m)*np.power(x[1],n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(35.15625, dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = np.array([1.5, 2.5])\n",
    "dx_ = np.array([.1, .1])\n",
    "q(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_classic(x, dx):\n",
    "    # for q = x[0]*x[1]\n",
    "    dq_ = q(x_)*np.sqrt(np.power(2*dx_[0]/x_[0],2)+np.power(3*dx_[1]/x_[1],2))\n",
    "    return dq_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  35.15625 +/- 6.3063865\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_classic(x_, dx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  35.15625 +/- 6.3063865\n"
     ]
    }
   ],
   "source": [
    "print('q = ', q(x_), '+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Examples\n",
    "\n",
    "See some examples here:\n",
    "\n",
    "http://www.geol.lsu.edu/jlorenzo/geophysics/uncertainties/Uncertaintiespart2.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:  `w = (4.52 ± 0.02) cm, A = (2.0 ± 0.2), y = (3.0 ± 0.6) cm`. Find\n",
    "\n",
    "\\begin{equation}\n",
    "z=\\frac{wy^2}{\\sqrt{A}}\n",
    "\\end{equation}\n",
    "\n",
    "The second relative error, (Dy/y), is multiplied by 2 because the power of y is 2.  \n",
    "The third relative error, (DA/A), is multiplied by 0.5 since a square root is a power of one half.\n",
    "\n",
    "So Dz = 0.49 (28.638  ) = 14.03  which we round to 14 \n",
    "\n",
    "z = (29 ± 14) \n",
    "Using Eq. 3b, \n",
    "z=(29 ± 12) \n",
    "Because the uncertainty begins with a 1, we keep two significant figures and round the answer to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return x[0]*x[2]*x[2]/np.sqrt(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q =  28.765104 +/- 11.596283\n"
     ]
    }
   ],
   "source": [
    "x_ = np.array([4.52, 2., 3.]) #w,A,y\n",
    "dx_ = np.array([.02, .2, .6])\n",
    "\n",
    "print('q = ', q(x_), '+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 30.050316 std =  11.813263\n"
     ]
    }
   ],
   "source": [
    "import numpy as onp  #using jax as np right now\n",
    "w_ = onp.random.normal(x_[0], dx_[0], 10000)\n",
    "A_ = onp.random.normal(x_[1], dx_[1], 10000)\n",
    "y_ = onp.random.normal(x_[2], dx_[2], 10000)\n",
    "x__ = np.vstack((w_, A_, y_))\n",
    "z_ = q(x__)\n",
    "print('mean =', np.mean(z_), 'std = ', np.std(z_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(z_, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also taken from http://www.geol.lsu.edu/jlorenzo/geophysics/uncertainties/Uncertaintiespart2.html\n",
    "\n",
    "\n",
    "`w = (4.52 ± 0.02) cm, x = (2.0 ± 0.2) cm, y = (3.0 ± 0.6) cm. `\n",
    "\n",
    "Find \n",
    "\\begin{equation}\n",
    "z = w x +y^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We have v = wx = (9.0 ± 0.9) cm.  \n",
    "The calculation of the uncertainty in  is the same as that shown to the left. Then from Eq. 1b \n",
    "Dz =  3.7  \n",
    "z = (18 ± 4) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    # [w,x,y]\n",
    "    return x[0]*x[1]+x[2]*x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.array([4.52, 2., 3.]) #w,x,y\n",
    "dx_ = np.array([.02, .2, .6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.04 +/- 3.711983\n"
     ]
    }
   ],
   "source": [
    "print(q(x_),'+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example with many inputs\n",
    "\n",
    "The code we used for `error_prop_jax_gen` is generic and supports functions `q` on any number of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = 1.*np.arange(1,101) #counts from 1-100 (and 1.* to make them floats)\n",
    "dx_ = 0.1*np.ones(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum from $1 to N$ is $N*(N+1)/2$  (see [the story of Gauss](https://hsm.stackexchange.com/questions/384/did-gauss-find-the-formula-for-123-ldotsn-2n-1n-in-elementary-school)), so we expect q(x)=5050. And the uncertainty should be $\\sqrt{100}*0.1$ = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050.0 +/- 1.0\n"
     ]
    }
   ],
   "source": [
    "print(q(x_),'+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another toy example... product from 1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x):\n",
    "    return np.product(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628800.0 +/- 451748.1\n"
     ]
    }
   ],
   "source": [
    "x_ = 1.*np.arange(1,11) #counts from 1-100 (and 1.* to make them floats)\n",
    "dx_ = 0.1*np.ones(10)\n",
    "print(q(x_),'+/-', error_prop_jax_gen(q, x_, dx_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking this is an exercise left to the reader :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
