

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta property="og:title" content="Quantifying statistical dependence" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://cranmer.github.io/stats-ds-book/measures_of_dependence.html" />
  <meta property="og:description" content="\newcommand\indep{\perp\kern-5pt\perp} As we saw earlier, two random variables may be uncorrelated(the covariance of two random variables may be zero), but that does not imply the two variables are..." />
  <meta property="og:image" content="https://cranmer.github.io/stats-ds-book/_images/Neyman-pearson.006.png" />
  
    <title>Quantifying statistical dependence &#8212; Statistics and Data Science</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/segment.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/menu.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_tabs/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/pdf_print.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-index--0afa1ebdab0bb23b98b56d34c23d9f57.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-variables--ffc7f74dcb1b9eecba2dbcbc22818714.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/save_state.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "indep": "{\\perp\\kern-5pt\\perp}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "bered": ["\\color{#DC2830}{#1}", 1], "ecol": ["}}"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="How do distributions transform under a change of variables ?" href="distributions/change-of-variables.html" />
    <link rel="prev" title="Visualizing joint and marginal distributions" href="distributions/visualize_marginals.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Statistics and Data Science</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Statistics and Data Science
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="schedule.html">
   Draft Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="jupyterhub.html">
   JupyterHub for class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discussion_forum.html">
   Discussion Forum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="preliminaries.html">
   Preliminaries
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Probability
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="reference internal" href="probability-topics.html">
   Probability Topics
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="random_variables.html">
     Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conditional.html">
     Conditonal Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bayes_theorem.html">
     Bayes’ Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="independence.html">
     Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="empirical_distribution.html">
     Empirical Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="expectation.html">
     Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="correlation.html">
     Covariance and Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="datasaurus-long.html">
     Simple data exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/visualize_marginals.html">
     Visualizing joint and marginal distributions
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Quantifying statistical dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/change-of-variables.html">
     How do distributions transform under a change of variables ?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/one-over-x-flow.html">
     Change of variables with autodiff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/likelihood-change-obs.html">
     Transformation of likelihood with change of random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/invariance-of-likelihood-to-reparameterizaton.html">
     Transformation properties of the likelihood and posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="error-propagation/investigating-propagation-of-errors.html">
     Investigating propagation of errors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="error-propagation/error_propagation_with_jax.html">
     Revisiting error propagation with automatic differentiation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/accept-reject.html">
     Accept / Reject Monte Carlo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="distributions/Binomial_histograms-interactive.html">
     An interactive exploration of statistical fluctuations in histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pgm/daft.html">
     Visualizing Graphical Models
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="statistics-topics.html">
   Statistics Topics
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_pearson.html">
     Neyman-Pearson lemma
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_construction.html">
     Neyman construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lhc_stats_thumbnail.html">
     Thumbnail of LHC Statistical Procedures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="statistical_decision_theory.html">
     Statistical decision theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="probprog/MarkovPath.html">
     Universal Probabilistic Programming Example
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="prml_notebooks/attribution.html">
   PRML Examples
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch01_Introduction.html">
     1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch02_Probability_Distributions.html">
     2. Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch03_Linear_Models_for_Regression.html">
     3. Linear Models for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch04_Linear_Models_for_Classfication.html">
     4. Linear Models for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch05_Neural_Networks.html">
     5. Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch06_Kernel_Methods.html">
     6. Kernel Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch07_Sparse_Kernel_Machines.html">
     7. Sparse Kernel Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch08_Graphical_Models.html">
     8. Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch09_Mixture_Models_and_EM.html">
     9. Mixture Models and EM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch10_Approximate_Inference.html">
     10. Approximate Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch11_Sampling_Methods.html">
     11. Sampling Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch12_Continuous_Latent_Variables.html">
     12. Continuous Latent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prml_notebooks/ch13_Sequential_Data.html">
     13. Sequential Data
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Software and Computing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="computing-topics.html">
   Software &amp; Computing Topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="autodiff-tutorial.html">
   Tutorial on Automatic Differentiation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data Science
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="data-science-topics.html">
   Data Science Topics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="other_resources.html">
   Other Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="built-on.html">
   Built on
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Jupyter Book Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cheatsheet.html">
   MyST Cheat Sheet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   Content with notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interactive.html">
   Interactive data visualizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="test_embed_video.html">
   Test Embed Video
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nbgrader.html">
   nbgrader
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/measures_of_dependence.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/cranmer/stats-ds-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/cranmer/stats-ds-book/issues/new?title=Issue%20on%20page%20%2Fmeasures_of_dependence.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/cranmer/stats-ds-book/edit/master/book/measures_of_dependence.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mutual-information">
   Mutual Information
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distance-correlation">
   Distance Correlation
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="quantifying-statistical-dependence">
<h1>Quantifying statistical dependence<a class="headerlink" href="#quantifying-statistical-dependence" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[\newcommand\indep{\perp\kern-5pt\perp}\]</div>
<p>As we saw earlier, two random variables may be <em>uncorrelated</em> (the covariance of two random variables may be zero), but that does not imply the two variables are independent.
This figure from the wikipedia article on <a class="reference external" href="http://en.wikipedia.org/wiki/Correlation_and_dependence">Correlation and Dependence</a> is a good illustration. The bottom row shows examples of two variables that are uncorrelated, but not statistically independent (eg. we can’t factorize the joint <span class="math notranslate nohighlight">\(p(X,Y)\)</span> as <span class="math notranslate nohighlight">\(p(X)p(Y)\)</span>).</p>
<p><a href="https://commons.wikimedia.org/wiki/File:Correlation_examples2.svg#/media/File:Correlation_examples2.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/500px-Correlation_examples2.svg.png" width="80%" alt="Correlation examples2.svg">
</a></p>
<p>So how can we quantify if and two what degree two variables are statistically dependent?</p>
<div class="section" id="mutual-information">
<h2>Mutual Information<a class="headerlink" href="#mutual-information" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_information"><strong>Mutual information</strong></a> is
of two random variables is a measure of the mutual dependence between the two variables. It quantifies the “amount of information”  obtained about one random variable through observing the other random variable. The concept of mutual information is intimately linked to that of entropy of a random variable, a fundamental notion in information theory that quantifies the expected “amount of information” held in a random variable.<a class="footnote-reference brackets" href="#footnote1" id="id1">1</a></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The <strong>mutual information</strong> <span class="math notranslate nohighlight">\(I(X;Y)=0\)</span> <em>if and only if</em> <span class="math notranslate nohighlight">\(X \indep Y\)</span>.</p>
</div>
<p>The mutual information of two jointly discrete random variables
<span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is calculated as a double sum</p>
<div class="math notranslate nohighlight">
\[
{\displaystyle \operatorname {I} (X;Y)=\sum _{y\in {\mathcal {Y}}}\sum _{x\in {\mathcal {X}}}{p_{(X,Y)}(x,y)\log {\left({\frac {p_{(X,Y)}(x,y)}{p_{X}(x)\,p_{Y}(y)}}\right)}},}
\]</div>
<p>where <span class="math notranslate nohighlight">\({\displaystyle p_{(X,Y)}}\)</span> is the joint probability mass function of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(p_{X}\)</span> and <span class="math notranslate nohighlight">\(p_Y\)</span> are the marginal probability mass functions.<span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> respectively.</p>
<p>In the case of jointly continuous random variables, the double sum is replaced by a double integral</p>
<div class="math notranslate nohighlight">
\[
{\displaystyle \operatorname {I} (X;Y)=\int _{\mathcal {Y}}\int _{\mathcal {X}}{p_{(X,Y)}(x,y)\log {\left({\frac {p_{(X,Y)}(x,y)}{p_{X}(x)\,p_{Y}(y)}}\right)}}\;dx\,dy,}
\]</div>
<p>where <span class="math notranslate nohighlight">\({\displaystyle p_{(X,Y)}}\)</span> is now the joint probability density function and <span class="math notranslate nohighlight">\(p_{X}\)</span> and <span class="math notranslate nohighlight">\(p_Y\)</span> are the marginal probability density functions.</p>
<p>If the log base 2 is used, the units of mutual information are bits.</p>
<p>An equivalent formulation is</p>
<div class="math notranslate nohighlight">
\[
{\displaystyle I(X;Y)=D_{\mathrm {KL} }(P_{(X,Y)}\|P_{X}\otimes P_{Y})}
\]</div>
<p>where
<span class="math notranslate nohighlight">\(D_{{{\mathrm  {KL}}}}\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler</a> divergence, which we will return to later in the course. Here we see that it is the KL distance between the joint and the product of the two marginals, and so it is only zero if the those are identical, which is equivalent to saying <span class="math notranslate nohighlight">\(p(X,Y)= p(X)p(Y)\)</span>, which is the definition of independence.</p>
<p>Another useful identity is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
{\displaystyle {\begin{aligned}\operatorname {I} (X;Y)&amp;{}\equiv \mathrm {H} (X)-\mathrm {H} (X|Y)\\&amp;{}\equiv \mathrm {H} (Y)-\mathrm {H} (Y|X)\\&amp;{}\equiv \mathrm {H} (X)+\mathrm {H} (Y)-\mathrm {H} (X,Y)\\&amp;{}\equiv \mathrm {H} (X,Y)-\mathrm {H} (X|Y)-\mathrm {H} (Y|X)\end{aligned}}}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\({\displaystyle \mathrm {H} (X)}\)</span> and <span class="math notranslate nohighlight">\({\displaystyle \mathrm {H} (Y)}\)</span> are the marginal <a class="reference external" href="https://en.wikipedia.org/wiki/Information_entropy">entropies</a>,
<span class="math notranslate nohighlight">\({\displaystyle \mathrm {H} (X|Y)}\)</span> and <span class="math notranslate nohighlight">\({\displaystyle \mathrm {H} (Y|X)}\)</span> are the <a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_entropy">conditional entropies</a>, and
<span class="math notranslate nohighlight">\({\displaystyle \mathrm {H} (X,Y)}\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Joint_entropy">joint entropy</a> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The mutual information is symmetric <span class="math notranslate nohighlight">\(I(X;Y)=I(Y;X)\)</span> and non-negative <span class="math notranslate nohighlight">\(I(X;Y)\ge 0\)</span>.</p>
</div>
</div>
<div class="section" id="distance-correlation">
<h2>Distance Correlation<a class="headerlink" href="#distance-correlation" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Distance_correlation">Distance Correlation</a>  is a measure of dependence between two paired random vectors of arbitrary, not necessarily equal, dimension.
Thus, distance correlation measures both linear and nonlinear association between two random variables or random vectors. This is in contrast to Pearson’s correlation, which can only detect linear association between two random variables <a class="footnote-reference brackets" href="#footnote2" id="id2">2</a>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The <strong>distance correlation</strong> is zero  <em>if and only if</em> <span class="math notranslate nohighlight">\(X \indep Y\)</span>.</p>
</div>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="footnote1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Adapted from <a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_information">https://en.wikipedia.org/wiki/Mutual_information</a></p>
</dd>
<dt class="label" id="footnote2"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Adapted from <a class="reference external" href="https://en.wikipedia.org/wiki/Distance_correlation">https://en.wikipedia.org/wiki/Distance_correlation</a></p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="distributions/visualize_marginals.html" title="previous page">Visualizing joint and marginal distributions</a>
    <a class='right-next' id="next-link" href="distributions/change-of-variables.html" title="next page">How do distributions transform under a change of variables ?</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Kyle Cranmer<br/>
        
            &copy; Copyright .<br/>
          <div class="extra_footer">
            <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>